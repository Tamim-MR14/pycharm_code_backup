{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass                                               Name  \\\n",
      "0           0       3                            Braund, Mr. Owen Harris   \n",
      "1           1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2           1       3                             Heikkinen, Miss. Laina   \n",
      "3           1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4           0       3                           Allen, Mr. William Henry   \n",
      "5           0       3                                   Moran, Mr. James   \n",
      "6           0       1                            McCarthy, Mr. Timothy J   \n",
      "7           0       3                     Palsson, Master. Gosta Leonard   \n",
      "8           1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
      "9           1       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
      "10          1       3                    Sandstrom, Miss. Marguerite Rut   \n",
      "11          1       1                           Bonnell, Miss. Elizabeth   \n",
      "12          0       3                     Saundercock, Mr. William Henry   \n",
      "13          0       3                        Andersson, Mr. Anders Johan   \n",
      "14          0       3               Vestrom, Miss. Hulda Amanda Adolfina   \n",
      "15          1       2                   Hewlett, Mrs. (Mary D Kingcome)    \n",
      "16          0       3                               Rice, Master. Eugene   \n",
      "17          1       2                       Williams, Mr. Charles Eugene   \n",
      "18          0       3  Vander Planke, Mrs. Julius (Emelia Maria Vande...   \n",
      "19          1       3                            Masselmani, Mrs. Fatima   \n",
      "20          0       2                               Fynney, Mr. Joseph J   \n",
      "21          1       2                              Beesley, Mr. Lawrence   \n",
      "22          1       3                        McGowan, Miss. Anna \"Annie\"   \n",
      "23          1       1                       Sloper, Mr. William Thompson   \n",
      "24          0       3                      Palsson, Miss. Torborg Danira   \n",
      "25          1       3  Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...   \n",
      "26          0       3                            Emir, Mr. Farred Chehab   \n",
      "27          0       1                     Fortune, Mr. Charles Alexander   \n",
      "28          1       3                      O'Dwyer, Miss. Ellen \"Nellie\"   \n",
      "29          0       3                                Todoroff, Mr. Lalio   \n",
      "..        ...     ...                                                ...   \n",
      "861         0       2                        Giles, Mr. Frederick Edward   \n",
      "862         1       1  Swift, Mrs. Frederick Joel (Margaret Welles Ba...   \n",
      "863         0       3                  Sage, Miss. Dorothy Edith \"Dolly\"   \n",
      "864         0       2                             Gill, Mr. John William   \n",
      "865         1       2                           Bystrom, Mrs. (Karolina)   \n",
      "866         1       2                       Duran y More, Miss. Asuncion   \n",
      "867         0       1               Roebling, Mr. Washington Augustus II   \n",
      "868         0       3                        van Melkebeke, Mr. Philemon   \n",
      "869         1       3                    Johnson, Master. Harold Theodor   \n",
      "870         0       3                                  Balkic, Mr. Cerin   \n",
      "871         1       1   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n",
      "872         0       1                           Carlsson, Mr. Frans Olof   \n",
      "873         0       3                        Vander Cruyssen, Mr. Victor   \n",
      "874         1       2              Abelson, Mrs. Samuel (Hannah Wizosky)   \n",
      "875         1       3                   Najib, Miss. Adele Kiamie \"Jane\"   \n",
      "876         0       3                      Gustafsson, Mr. Alfred Ossian   \n",
      "877         0       3                               Petroff, Mr. Nedelio   \n",
      "878         0       3                                 Laleff, Mr. Kristo   \n",
      "879         1       1      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)   \n",
      "880         1       2       Shelley, Mrs. William (Imanita Parrish Hall)   \n",
      "881         0       3                                 Markun, Mr. Johann   \n",
      "882         0       3                       Dahlberg, Miss. Gerda Ulrika   \n",
      "883         0       2                      Banfield, Mr. Frederick James   \n",
      "884         0       3                             Sutehall, Mr. Henry Jr   \n",
      "885         0       3               Rice, Mrs. William (Margaret Norton)   \n",
      "886         0       2                              Montvila, Rev. Juozas   \n",
      "887         1       1                       Graham, Miss. Margaret Edith   \n",
      "888         0       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889         1       1                              Behr, Mr. Karl Howell   \n",
      "890         0       3                                Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex        Age  SibSp      Fare Embarked  new  \n",
      "0      male  22.000000      1    7.2500        S    0  \n",
      "1    female  38.000000      1   71.2833        C    1  \n",
      "2    female  26.000000      0    7.9250        S    0  \n",
      "3    female  35.000000      1   53.1000        S    1  \n",
      "4      male  35.000000      0    8.0500        S    0  \n",
      "5      male  29.699118      0    8.4583        Q    0  \n",
      "6      male  54.000000      0   51.8625        S    0  \n",
      "7      male   2.000000      3   21.0750        S    0  \n",
      "8    female  27.000000      0   11.1333        S    0  \n",
      "9    female  14.000000      1   30.0708        C    0  \n",
      "10   female   4.000000      1   16.7000        S    0  \n",
      "11   female  58.000000      0   26.5500        S    1  \n",
      "12     male  20.000000      0    8.0500        S    0  \n",
      "13     male  39.000000      1   31.2750        S    0  \n",
      "14   female  14.000000      0    7.8542        S    0  \n",
      "15   female  55.000000      0   16.0000        S    0  \n",
      "16     male   2.000000      4   29.1250        Q    0  \n",
      "17     male  29.699118      0   13.0000        S    0  \n",
      "18   female  31.000000      1   18.0000        S    0  \n",
      "19   female  29.699118      0    7.2250        C    0  \n",
      "20     male  35.000000      0   26.0000        S    0  \n",
      "21     male  34.000000      0   13.0000        S    0  \n",
      "22   female  15.000000      0    8.0292        Q    0  \n",
      "23     male  28.000000      0   35.5000        S    0  \n",
      "24   female   8.000000      3   21.0750        S    0  \n",
      "25   female  38.000000      1   31.3875        S    0  \n",
      "26     male  29.699118      0    7.2250        C    0  \n",
      "27     male  19.000000      3  263.0000        S    0  \n",
      "28   female  29.699118      0    7.8792        Q    0  \n",
      "29     male  29.699118      0    7.8958        S    0  \n",
      "..      ...        ...    ...       ...      ...  ...  \n",
      "861    male  21.000000      1   11.5000        S    0  \n",
      "862  female  48.000000      0   25.9292        S    1  \n",
      "863  female  29.699118      8   69.5500        S    0  \n",
      "864    male  24.000000      0   13.0000        S    0  \n",
      "865  female  42.000000      0   13.0000        S    0  \n",
      "866  female  27.000000      1   13.8583        C    0  \n",
      "867    male  31.000000      0   50.4958        S    0  \n",
      "868    male  29.699118      0    9.5000        S    0  \n",
      "869    male   4.000000      1   11.1333        S    0  \n",
      "870    male  26.000000      0    7.8958        S    0  \n",
      "871  female  47.000000      1   52.5542        S    1  \n",
      "872    male  33.000000      0    5.0000        S    0  \n",
      "873    male  47.000000      0    9.0000        S    0  \n",
      "874  female  28.000000      1   24.0000        C    0  \n",
      "875  female  15.000000      0    7.2250        C    0  \n",
      "876    male  20.000000      0    9.8458        S    0  \n",
      "877    male  19.000000      0    7.8958        S    0  \n",
      "878    male  29.699118      0    7.8958        S    0  \n",
      "879  female  56.000000      0   83.1583        C    1  \n",
      "880  female  25.000000      0   26.0000        S    0  \n",
      "881    male  33.000000      0    7.8958        S    0  \n",
      "882  female  22.000000      0   10.5167        S    0  \n",
      "883    male  28.000000      0   10.5000        S    0  \n",
      "884    male  25.000000      0    7.0500        S    0  \n",
      "885  female  39.000000      0   29.1250        Q    0  \n",
      "886    male  27.000000      0   13.0000        S    0  \n",
      "887  female  19.000000      0   30.0000        S    1  \n",
      "888  female  29.699118      1   23.4500        S    0  \n",
      "889    male  26.000000      0   30.0000        C    0  \n",
      "890    male  32.000000      0    7.7500        Q    0  \n",
      "\n",
      "[891 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best feature columns: (0, 2, 7, 8, 11)\n",
      "0.825842696629\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"titanicOriginalDataset.csv\")\n",
    "\n",
    "#Fillinf Missing values with a scalar value\n",
    "df['Age']=df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "#Filling NA with maximum occured group\n",
    "MaxEmbarked=df['Embarked'].dropna().max()\n",
    "df['Embarked']=df['Embarked'].fillna(MaxEmbarked)\n",
    "\n",
    "#Getting Maximum Count of a group in a collumn\n",
    "#max(df.groupby('Embarked').size())\n",
    "\n",
    "#Dropping Collumn of a Dataframe\n",
    "cols_drop=['PassengerId','Parch','Ticket','Cabin']\n",
    "df=df.drop(cols_drop,axis=1)\n",
    "\n",
    "#Creating new feature\n",
    "df['new'] = (df['Pclass']==1) & (df['Sex']=='female')\n",
    "df[\"new\"] = LabelEncoder().fit_transform(df[\"new\"])\n",
    "print(df)\n",
    "#One-hot-Encoding\n",
    "df=pd.get_dummies(df,columns=[\"Pclass\",\"Sex\",\"Embarked\"])\n",
    "\n",
    "#Extracting a portion from values of a collumn\n",
    "df['Name']=df['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "#Label_encoding\n",
    "df[\"Name\"] = LabelEncoder().fit_transform(df[\"Name\"])\n",
    "\n",
    "\n",
    "\n",
    "#Number of unique value in a series\n",
    "#len(df['Name'].unique())\n",
    "\n",
    "'''target=df['Survived'].values\n",
    "data=df.drop('Survived',axis=1).values\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(data, target,test_size=0.2)'''\n",
    "\n",
    "'''DT=DecisionTreeClassifier( )\n",
    "sfs1 = SFS(DT, k_features=3, forward=True, floating=False, scoring='accuracy', cv=10)\n",
    "sfs1 = sfs1.fit(X_train, Y_train)\n",
    "print('best feature columns:', sfs1.k_feature_idx_)\n",
    "\n",
    "X_train_sfs = sfs1.transform(np.array(X_train))\n",
    "X_test_sfs = sfs1.transform(np.array(X_test))\n",
    "\n",
    "DT.fit(X_train_sfs, Y_train)\n",
    "print(DT.score(X_test_sfs,Y_test))'''\n",
    "\n",
    "\n",
    "\n",
    "'''clf = MLPClassifier(max_iter = 200, solver='lbfgs', hidden_layer_sizes = (50,50), activation='relu')\n",
    "sfs1 = SFS(clf, k_features=5, forward=True, floating=False, scoring='accuracy', cv=10)\n",
    "sfs1 = sfs1.fit(X_train, Y_train)\n",
    "print('best feature columns:', sfs1.k_feature_idx_)\n",
    "\n",
    "X_train_sfs = sfs1.transform(np.array(X_train))\n",
    "X_test_sfs = sfs1.transform(np.array(X_test))\n",
    "\n",
    "clf.fit(X_train_sfs, Y_train)\n",
    "print(clf.score(X_test_sfs,Y_test))'''\n",
    "\n",
    "#Cross Validation using dataframe\n",
    "\n",
    "'''k=10\n",
    "l=int(len(df)/k)\n",
    "\n",
    "target=df['Survived'].values\n",
    "data=df.drop('Survived',axis=1).values\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(data, target,test_size=(l/len(df)))\n",
    "DT=DecisionTreeClassifier( )\n",
    "sfs1 = SFS(DT, k_features=5, forward=True, floating=False, scoring='accuracy', cv=10)\n",
    "sfs1 = sfs1.fit(X_train, Y_train)\n",
    "print('best feature columns:', sfs1.k_feature_idx_)\n",
    "\n",
    "\n",
    "i=0\n",
    "acc=0\n",
    "for m in range(k):\n",
    "    if m==k-1:\n",
    "        test_df=df.iloc[i:len(df)-1,:]\n",
    "        test_df.index=range(len(test_df))\n",
    "        train_indexes = set(range(df.shape[0])) - set(range(i,len(df)))\n",
    "        train_df = df.take(list(train_indexes))\n",
    "        train_df.index=range(len(train_df))\n",
    "    else:\n",
    "        test_df=df.iloc[i:i+l,:]\n",
    "        test_df.index=range(len(test_df))\n",
    "        train_indexes = set(range(df.shape[0])) - set(range(i,i+l))\n",
    "        train_df = df.take(list(train_indexes))\n",
    "        train_df.index=range(len(train_df))\n",
    "        \n",
    "    Y_train=train_df['Survived'].values\n",
    "    X_train=train_df.drop('Survived',axis=1).values\n",
    "    Y_test=test_df['Survived'].values\n",
    "    X_test=test_df.drop('Survived',axis=1).values\n",
    "    \n",
    "    \n",
    "    #sfs1 = sfs1.fit(X_train, Y_train)\n",
    "    #print('best feature columns:', sfs1.k_feature_idx_)\n",
    "    X_train_sfs = sfs1.transform(np.array(X_train))\n",
    "    X_test_sfs = sfs1.transform(np.array(X_test))\n",
    "    DT.fit(X_train_sfs, Y_train)\n",
    "    acc=acc+DT.score(X_test_sfs,Y_test)\n",
    "    i=i+l\n",
    "print(acc/k)'''\n",
    "\n",
    "#Cross Validation using array\n",
    "k=10\n",
    "i=0\n",
    "l=int(len(df)/k)\n",
    "acc=0\n",
    "target=df['Survived'].values\n",
    "data=df.drop('Survived',axis=1).values\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(data, target,test_size=(l/len(df)))\n",
    "DT=DecisionTreeClassifier( )\n",
    "sfs1 = SFS(DT, k_features=5, forward=True, floating=False, scoring='accuracy', cv=10)\n",
    "sfs1 = sfs1.fit(X_train, Y_train)\n",
    "print('best feature columns:', sfs1.k_feature_idx_)\n",
    "for m in range(k):\n",
    "    X_train=[]\n",
    "    X_test=[]\n",
    "    Y_train=[]\n",
    "    Y_test=[]\n",
    "    s=0\n",
    "    t=0\n",
    "    if m==(k-1):\n",
    "        '''for j in range(len(data)):\n",
    "            if j in range(i,len(data)):\n",
    "                X_test.append([])\n",
    "                Y_test.append([])\n",
    "                X_test[s].append(data[j])\n",
    "                Y_test[s].append(target[j])\n",
    "                s+=1\n",
    "            else:\n",
    "                X_train.append([])\n",
    "                Y_train.append([])\n",
    "                X_train[t].append(data[j])\n",
    "                Y_train[t].append(target[j])\n",
    "                t+=1'''\n",
    "        X_test=data[i:len(data)-1,:]\n",
    "        Y_test=target[i:len(data)-1]\n",
    "        train_indexes = set(range(data.shape[0])) - set(range(i,len(data)))\n",
    "        X_train=data[list(train_indexes),:]\n",
    "        Y_train=target[list(train_indexes)]\n",
    "    else:\n",
    "        '''for j in range(len(data)):\n",
    "            if j in range(i,l):\n",
    "                X_test.append([])\n",
    "                Y_test.append([])\n",
    "                X_test[s].append(data[j])\n",
    "                Y_test[s].append(target[j])\n",
    "                s+=1\n",
    "            else:\n",
    "                X_train.append([])\n",
    "                Y_train.append([])\n",
    "                X_train[t].append(data[j])\n",
    "                Y_train[t].append(target[j])\n",
    "                t+=1'''\n",
    "        X_test=data[i:i+l,:]\n",
    "        Y_test=target[i:i+l]\n",
    "        train_indexes = set(range(data.shape[0])) - set(range(i,i+l))\n",
    "        X_train = data[list(train_indexes),:]\n",
    "        Y_train=target[list(train_indexes)]    \n",
    "    X_train_sfs = sfs1.transform(np.array(X_train))\n",
    "    X_test_sfs = sfs1.transform(np.array(X_test))\n",
    "    DT.fit(X_train_sfs, Y_train)\n",
    "    acc=acc+DT.score(X_test_sfs,Y_test)\n",
    "    i=i+l\n",
    "print(acc/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
