{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71002.0, 71052.50000000001, 95.0, 38.4, 9.399999999999999, 323.09999999999997, 707.1999999999998, 2.9999999999999885, 3629, 2172, 450.2], [70843.4, 70893.39999999997, 61.800000000000004, 16.499999999999996, 4.5, 397.9999999999999, 790.3999999999997, 41.3, 3540, 2072, 476.9999999999999], [70658.3, 70708.49999999999, 32.7, 10.9, 2.9, 288.0, 687.6999999999996, -65.79999999999997, 3354, 1778, 497.9], [71242.0, 71292.59999999999, 254.1, 61.29999999999999, 14.900000000000002, 353.69999999999993, 653.1, 95.79999999999998, 4071, 2831, 327.8000000000001], [70746.69999999998, 71057.19999999997, 59.5, 22.0, 7.5, 321.8000000000001, 631.4000000000001, 33.59999999999999, 3726, 2470, 456.30000000000007], [70948.60000000002, 71260.0, 102.3, 28.1, 7.999999999999998, 360.5000000000001, 651.5000000000001, 70.60000000000001, 3678, 2563, 419.5999999999999], [70672.19999999998, 70981.6, 87.0, 31.0, 11.5, 391.5999999999999, 720.5000000000002, 65.39999999999999, 3109, 1945, 503.09999999999997], [70847.49999999999, 71158.09999999999, 171.5, 46.5, 16.0, 392.2999999999999, 666.2000000000002, 117.09999999999998, 4024, 2790, 298.50000000000006], [70750.2, 71060.5, 117.5, 37.5, 12.0, 353.6000000000001, 662.2, 59.900000000000006, 3483, 2278, 417.30000000000024], [70780.9, 71090.5, 257.0, 68.0, 25.0, 419.49999999999994, 682.3000000000001, 179.90000000000003, 3951, 2843, 346.50000000000017], [70812.8, 71122.50000000003, 181.0, 58.5, 18.5, 454.0000000000001, 756.7000000000002, 186.90000000000003, 3603, 2424, 431.40000000000003], [70765.3, 71076.1, 121.0, 36.5, 10.5, 364.90000000000003, 673.2999999999998, 108.49999999999999, 3443, 2362, 412.6], [70679.7, 70990.20000000004, 174.5, 44.5, 12.5, 367.20000000000005, 660.2999999999996, 94.1, 3502, 2285, 428.00000000000006], [70770.20000000001, 71079.4, 136.0, 52.5, 18.5, 449.09999999999997, 764.9, 153.29999999999998, 3716, 2487, 400.6999999999999], [70827.99999999999, 71140.10000000002, 48.5, 18.0, 8.0, 328.49999999999994, 630.6999999999999, 48.599999999999994, 3411, 2168, 414.29999999999995], [70618.90000000001, 70928.20000000003, 100.5, 32.5, 17.0, 384.6, 677.6000000000001, 119.59999999999998, 3523, 2304, 391.40000000000003], [70685.59999999999, 70993.9, 158.5, 47.5, 17.0, 527.3000000000001, 818.0999999999999, 258.20000000000005, 3796, 2528, 416.90000000000003], [70698.99999999999, 71008.79999999997, 198.0, 54.5, 19.5, 399.69999999999993, 685.2000000000002, 136.59999999999997, 3461, 2320, 423.20000000000005], [70713.0, 71023.59999999999, 57.5, 20.5, 8.0, 358.1000000000001, 637.6, 101.2, 3438, 2173, 461.59999999999997], [70796.10000000002, 71105.79999999999, 108.5, 37.5, 13.5, 420.50000000000006, 695.0000000000001, 165.49999999999997, 3597, 2322, 424.1999999999998], [70876.8, 71186.50000000001, 99.5, 19.5, 6.0, 449.1999999999999, 731.2, 189.20000000000002, 3525, 2302, 485.80000000000007], [70735.09999999999, 71046.89999999997, 108.5, 33.0, 10.5, 256.20000000000005, 507.8999999999999, 16.2, 3604, 2284, 460.8], [70747.80000000002, 71058.40000000001, 57.5, 21.5, 6.5, 340.0000000000001, 606.0000000000001, 89.2, 3468, 2272, 432.00000000000006], [70746.2, 71054.70000000001, 96.0, 43.0, 14.0, 452.5, 738.9000000000001, 169.5999999999999, 3686, 2492, 413.90000000000003], [70846.5, 71155.79999999999, 57.5, 22.0, 6.5, 447.19999999999993, 720.8000000000001, 179.20000000000005, 3515, 2281, 432.8000000000001], [71004.70000000001, 71313.29999999999, 254.0, 76.5, 29.5, 554.6000000000001, 799.9000000000003, 320.50000000000006, 3995, 2820, 335.3999999999999], [71083.70000000001, 71393.5, 168.5, 51.0, 21.5, 476.29999999999995, 705.4000000000003, 266.59999999999997, 4006, 2873, 321.20000000000005], [70706.29999999999, 71014.5, 160.5, 59.0, 21.5, 473.2999999999999, 744.6, 218.29999999999998, 3368, 2123, 461.8999999999999], [70807.90000000001, 71116.0, 146.5, 35.5, 12.5, 498.9, 758.8000000000002, 244.60000000000002, 3773, 2531, 387.70000000000005], [70785.50000000001, 71093.80000000002, 180.5, 65.0, 21.5, 496.9999999999999, 745.2999999999998, 253.4, 3747, 2506, 393.2], [70721.29999999999, 71029.8, 142.0, 39.0, 12.5, 456.4000000000001, 723.8, 199.00000000000003, 3365, 2171, 466.5999999999999], [70748.8, 71057.90000000001, 88.0, 39.0, 13.5, 428.1, 704.0000000000001, 168.5, 3351, 2222, 458.29999999999984], [70698.30000000002, 71006.40000000001, 50.5, 16.0, 6.5, 526.2999999999998, 829.4000000000001, 244.29999999999995, 3299, 1948, 497.1], [70919.0, 71229.60000000003, 297.0, 62.5, 18.5, 448.1, 742.8000000000001, 195.49999999999997, 4115, 2694, 397.1], [70684.40000000001, 70992.4, 74.5, 23.5, 8.5, 494.1, 788.3000000000001, 206.99999999999997, 3228, 1980, 469.4000000000001], [70782.20000000001, 71090.59999999999, 79.5, 29.0, 11.5, 492.3000000000001, 763.5000000000002, 241.79999999999993, 3095, 1935, 430.6999999999999], [70731.9, 71041.1, 195.5, 50.0, 13.0, 420.0, 702.2000000000002, 168.30000000000007, 3315, 2085, 396.8], [70742.6, 71049.3, 125.5, 47.5, 22.0, 567.0000000000003, 851.4, 301.79999999999995, 3279, 2105, 430.49999999999994], [70778.49999999999, 71088.8, 276.0, 100.0, 28.0, 423.19999999999993, 686.9000000000001, 188.39999999999995, 3377, 2135, 429.79999999999995], [70726.19999999998, 71033.59999999996, 27.5, 15.5, 5.5, 514.3, 803.0, 250.50000000000003, 3072, 1836, 483.90000000000015], [70727.19999999998, 71041.6, 157.5, 40.5, 13.0, 437.70000000000005, 710.3999999999997, 185.29999999999993, 3338, 2177, 403.70000000000005], [70968.40000000001, 71283.40000000002, 218.5, 58.5, 16.5, 441.09999999999997, 694.9999999999997, 214.69999999999993, 3461, 2348, 343.2999999999999], [70916.0, 71228.29999999999, 144.0, 64.0, 19.5, 595.7, 852.6999999999998, 355.5999999999999, 3181, 2076, 431.90000000000003], [70844.70000000001, 71159.5, 261.5, 68.5, 21.5, 517.7, 765.5999999999999, 292.4, 3432, 2314, 341.9], [70812.09999999999, 71126.80000000002, 179.5, 56.0, 18.5, 482.9999999999999, 745.6000000000003, 224.1, 3699, 2586, 376.00000000000006], [70746.80000000002, 71062.30000000003, 193.5, 47.0, 13.0, 422.7, 707.7999999999998, 165.69999999999993, 3062, 1956, 459.2000000000002], [70843.50000000004, 71159.40000000002, 241.0, 55.5, 18.0, 386.7, 631.4, 171.70000000000002, 3540, 2410, 345.69999999999993], [70841.80000000003, 71156.70000000001, 117.0, 35.0, 11.0, 468.59999999999997, 765.9000000000002, 199.79999999999998, 3298, 2006, 466.3999999999999], [70960.70000000003, 71276.80000000002, 230.0, 58.0, 17.0, 430.19999999999993, 710.4, 191.30000000000004, 3428, 2213, 409.6999999999999], [70841.29999999999, 71049.90000000001, 233.0, 79.5, 23.0, 424.49999999999994, 742.4000000000001, 157.4, 3931, 2446, 392.09999999999985], [71048.99999999997, 71257.7, 197.0, 49.0, 16.0, 497.80000000000007, 832.1999999999997, 207.99999999999994, 3964, 2515, 415.5], [70784.1, 70993.09999999999, 57.0, 19.0, 7.0, 461.20000000000005, 812.9000000000002, 161.70000000000002, 3648, 2275, 490.10000000000014]]\n",
      "[[70736.70000000001, 71045.19999999998, 163.5, 57.699999999999996, 17.9, 450.7, 754.9999999999999, 140.59999999999997, 3622, 2490, 379.40000000000003], [70748.39999999998, 71059.3, 89.5, 33.5, 10.5, 380.19999999999993, 666.3000000000003, 124.4, 3503, 2324, 414.2], [70802.40000000001, 71112.89999999998, 186.5, 33.5, 12.5, 387.7, 652.5999999999999, 153.40000000000003, 3918, 2731, 373.3], [70660.00000000001, 70969.20000000001, 185.5, 56.5, 16.5, 434.7999999999999, 692.4, 202.00000000000006, 3631, 2418, 421.69999999999993], [70840.29999999999, 71155.5, 83.0, 33.0, 11.5, 426.90000000000003, 696.1000000000001, 182.7, 2997, 1855, 451.2999999999999]]\n",
      "52\n",
      "11\n",
      "5\n",
      "[91, 91, 91, 93, 92, 89, 89, 96, 97, 88, 90, 92, 88, 82, 81, 90, 82, 91, 85, 82, 90, 102, 93, 82, 93, 79, 79, 89, 84, 83, 90, 91, 80, 86, 83, 90, 82, 75, 86, 78, 90, 80, 79, 80, 81, 87, 91, 75, 84, 82, 81, 80]\n",
      "[79, 89, 93, 90, 82]\n",
      "52\n",
      "5\n",
      "best feature columns: (1, 4, 5, 7, 9)\n",
      "Test score 0.880156383944\n",
      "Train_score 0.52638501106\n",
      "[77, 91, 93, 88, 83]\n",
      "0.905247813411\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "#training=[]\n",
    "#test=[]\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "df=pd.read_csv(\"modified tokyo.csv\")\n",
    "k=0\n",
    "m=0\n",
    "for i in range(1961,2018):\n",
    "    #bdi=df.loc[(df['year'] == i) & df['bloom'].isin([1])].index.tolist()\n",
    "    #df2=df.loc[(df['year'] == i) & (df['serial']<=bdi[0])]\n",
    "    #df2.index=range(len(df2))\n",
    "    df2=df.loc[df['year'].isin([i])]\n",
    "    df2.index=range(len(df2))\n",
    "    df2=df2.iloc[:70,:]\n",
    "    if i in [1966,1971,1985,1994,2008]:\n",
    "        continue\n",
    "        \n",
    "    #training.append([])\n",
    "    X_train.append([])\n",
    "    #for j in range(6,12):\n",
    "        #training[m].append(df2.iloc[:,j].mean())\n",
    "        #X_train[m].append(df2.iloc[:,j].mean())\n",
    "    for j in range(4,15):\n",
    "        #training[m].append(df2.iloc[:,j].sum())\n",
    "        X_train[m].append(df2.iloc[:,j].sum())\n",
    "    m+=1\n",
    "\n",
    "for i in [1966,1971,1985,1994,2008]:\n",
    "    #df2=df.loc[(df['year'] == i)]\n",
    "    #df2.index=range(len(df2))\n",
    "    #df2=df2.iloc[0:60,:]\n",
    "    df2=df.loc[df['year'].isin([i])]\n",
    "    df2.index=range(len(df2))\n",
    "    df2=df2.iloc[:70,:]\n",
    "    \n",
    "    #test.append([])\n",
    "    X_test.append([])\n",
    "    #for j in range(6,12):\n",
    "        #test[k].append(df2.iloc[:,j].mean())\n",
    "        #X_test[k].append(df2.iloc[:,j].mean())\n",
    "    for j in range(4,15):\n",
    "        #test[k].append(df2.iloc[:,j].sum())\n",
    "        X_test[k].append(df2.iloc[:,j].sum())\n",
    "    k+=1\n",
    "\n",
    "k=0\n",
    "m=0\n",
    "\n",
    "for i in range(1961,2018):\n",
    "    bdi=df.loc[(df['year'] == i) & df['bloom'].isin([1])].index.tolist()\n",
    "    df2=df.loc[(df['year'] == i) & (df['serial']<=bdi[0])]\n",
    "    df2.index=range(len(df2))\n",
    "    \n",
    "    if i in [1966,1971,1985,1994,2008]:\n",
    "        bdi=df2.loc[(df2['year'] == i) & df2['bloom'].isin([1])].index.tolist()\n",
    "        #test[k].append(bdi[0]+1)\n",
    "        Y_test.append(bdi[0]+1)\n",
    "        k+=1\n",
    "        continue\n",
    "    \n",
    "    bdi=df2.loc[(df2['year'] == i) & df2['bloom'].isin([1])].index.tolist()\n",
    "    #training[m].append(bdi[0]+1)\n",
    "    Y_train.append(bdi[0]+1)\n",
    "    m+=1\n",
    "    \n",
    "    \n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(len(X_train))\n",
    "print(len(X_train[0]))\n",
    "print(len(X_test))\n",
    "#X_train=np.array(training)[:,:1]\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "#print(X_train)\n",
    "\n",
    "#Y_train=np.array(training)[:,-1:].ravel()\n",
    "print(Y_train)\n",
    "print(Y_test)\n",
    "print(len(Y_train))\n",
    "print(len(Y_test))\n",
    "#print(np.mean(Y_train))\n",
    "#X_test=np.array(test)[:,:1]\n",
    "X_test_scaled=scaler.fit_transform(X_test)\n",
    "#print(X_test)\n",
    "\n",
    "#Y_test=np.array(test)[:,-1:].ravel()\n",
    "#print(Y_test)\n",
    "\n",
    "\n",
    "clf = MLPRegressor(max_iter = 200, solver='lbfgs', hidden_layer_sizes = (50,50), activation='identity')\n",
    "sfs = SFS(clf,k_features=5,forward=True,floating=False,scoring='r2',cv=10)\n",
    "sfs = sfs.fit(np.array(X_train_scaled),np.array(Y_train))\n",
    "print('best feature columns:', sfs.k_feature_idx_)\n",
    "X_train_sfs = sfs.transform(np.array(X_train_scaled))\n",
    "X_test_sfs = sfs.transform(np.array(X_test_scaled))\n",
    "\n",
    "#print(X_train_sfs)\n",
    "#print(X_test_sfs)\n",
    "\n",
    "out=0\n",
    "train_out=0\n",
    "Y_pred=[0,0,0,0,0]\n",
    "for i in range(50):\n",
    "    #clf=MLPRegressor(hidden_layer_sizes=(50,50),activation='relu', solver='lbfgs',max_iter=200)\n",
    "    #clf=clf.fit(X_train,Y_train)\n",
    "    clf.fit(X_train_sfs, Y_train)\n",
    "    Y=clf.predict(X_test_sfs)\n",
    "    Y_pred=[x + y for x, y in zip(Y_pred, Y)]\n",
    "    out=out+clf.score(X_test_sfs,Y_test)\n",
    "    train_out=train_out+clf.score(X_train_sfs,Y_train)\n",
    "    \n",
    "print('Test score',out/50)\n",
    "print('Train_score',train_out/50)\n",
    "Y_pred=[int(round(i/50)) for i in Y_pred]\n",
    "print(Y_pred)\n",
    "print(metrics.r2_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
